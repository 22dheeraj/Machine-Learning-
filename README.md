# ğŸ  Airbnb Price Prediction & Insights

## ğŸ“Œ Overview
Airbnb is a global platform that allows property owners to rent out their spaces to travelers.  
Setting the **right price** for a listing is crucial for:
- Staying competitive
- Attracting bookings
- Maximizing revenue

This project focuses on building a **machine learning regression model** to predict the price of an Airbnb listing using features such as:
- Property type
- Room type
- Location
- Amenities
- Host characteristics

Alongside prediction, the project also delivers **data-driven insights** that hosts can use to optimize their pricing strategy.

---

## ğŸ¯ Project Objective
Develop a **regression model** that predicts the nightly price of an Airbnb listing.  

The analysis aims to:
1. Identify the **key factors** that influence pricing.
2. Help hosts make **data-backed pricing decisions**.
3. Provide actionable insights for improving listing competitiveness.

---

## Dataset
- **Name:** `Airbnb_data`
- **Source:** Provided as part of the project

---

## ğŸ“¦ Project Deliverables

### **1. Data Exploration & Preprocessing **
- Explored dataset for patterns and trends.
- Identified and handled missing values and outliers.
- Performed feature engineering (e.g., number of amenities, neighborhood popularity).
- Applied transformations for model readiness.

### **2. Model Development **
- Trained and evaluated multiple regression algorithms:
  - Linear Regression
  - KNN Regression
  - Support Vector Machine(SVM)
  - Decision Tree Regressor
  - Random Forest Regressor
  - XGBoost Regressor
- Compared models on **RMSE**, **MAE**, and **RÂ²** scores.
- Selected the best-performing model for deployment.

### **3. Model Evaluation **
- Evaluated models on test set using:
  - RMSE (Root Mean Square Error)
  - MAE (Mean Absolute Error)
  - RÂ² (Coefficient of Determination)
- Ensured selected model had a good balance between accuracy and generalization.

- **Model Comparison Table:**

Final Model Evaluation Summary:
                      RÂ²   RMSE    MAE
XGBoost (Tuned)    0.717  0.381  0.276
Random Forest      0.699  0.393  0.283
SVM Regressor      0.637  0.432  0.314
Linear Regression  0.605  0.450  0.333
KNN Regressor      0.557  0.477  0.352
Decision Tree      0.402  0.554  0.397

---

## ğŸ“‹ Project Guidelines
- **Data Splitting:** Train-validation-test split for robust evaluation.
- **Feature Engineering:** Create meaningful derived variables.
- **Hyperparameter Tuning:** Used GridSearchCV/RandomizedSearchCV for optimization.
- **Visualization:** Included charts to present trends and results.
- **Interpretability:** Ensured non-technical stakeholders can understand findings.

---

## ğŸ›  Tools & Technologies
- **Programming Language:** Python  
- **Libraries:**
  - pandas, numpy â†’ Data processing
  - matplotlib, seaborn â†’ Visualization
  - scikit-learn â†’ Modeling (Linear Regression, KNN, SVM, Decision Tree, Random Forest, Gradient Boosting)
  - XGBoost â†’ Gradient boosting
- **Environment:** Jupyter Notebook
